{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*A Neural Network using pytorch and it's torch.nn module*"
      ],
      "metadata": {
        "id": "8r1YrKlv5gXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Ancrkyf6BG-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, first we import everything we will require to build our neural network."
      ],
      "metadata": {
        "id": "aCZbIQ-m56YQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTaR5Pv4DHeP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torch.nn.functional as F # All functions that don't have any parameters\n",
        "from torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\n",
        "import torchvision.datasets as datasets # Has standard datasets we can import easily\n",
        "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
        "import matplotlib.pyplot as plt # will be used to plot images from MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "RHM2CPqCBTof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we load the training and testing dataset. We also prepare the dataloaders that will iterate through the data in batches during our training phase"
      ],
      "metadata": {
        "id": "-UpsHSh9DgAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 #how many samples our model sees at once/ pass through the model at once\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\",\n",
        "    train=True,   # Since we will be using this for training\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\",\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trv6sNvLkYiF",
        "outputId": "b6d25804-4fa2-46c3-e81d-eb53f6243d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 102740044.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 30367433.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26622416.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3016710.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the dataset"
      ],
      "metadata": {
        "id": "sZ75DH4gBlqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over the next few cells we will try and understand what our dataset looks like and the kind of model we need to build"
      ],
      "metadata": {
        "id": "XjU2n1pCDRXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NX2Rw8VJL35",
        "outputId": "ea1aef9c-f591-458c-b0f0-7a68f0e183c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M00-Ee1vJTR1",
        "outputId": "ece8ba3c-6f44-4468-dc46-c74679a26301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBD9VXh23W_",
        "outputId": "86d8f092-ef8b-46e2-c9d3-3382b5221d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_dataset[0][0].squeeze().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "uzytpLL870tV",
        "outputId": "ff272bb4-c64c-4654-ef35-1316f84e3637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "6cUqgmqnBtay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will be initialising the hyperparameters, selecting the loss function & optimiser and building the architecture of the neural network"
      ],
      "metadata": {
        "id": "Ttg_mKkVDxCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size = 784 # 28x28 = 784, size of MNIST images (grayscale), we will compress the inputs from train_dataset during iterating later\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3"
      ],
      "metadata": {
        "id": "JinyZ5XQlUNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, num_classes)\n",
        "        # nn. Linear(n,m) is a module that creates single layer feed forward network with n inputs and m output.\n",
        "        # Mathematically, this module is designed to calculate the linear equation Ax = b where x is input, b is output, A is weight.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kdCzM6ni5NkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Sequential):  # alternative to using nn.module when just building a linear neural network\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__(\n",
        "           nn.Linear(input_size, 50),\n",
        "           nn.ReLU(),\n",
        "           nn.Linear(50, num_classes),\n",
        "           )"
      ],
      "metadata": {
        "id": "lQWs31IGlQKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "88-UhqcllbNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "\n",
        "  if batch_idx>935: # only printing the last 2 iterations\n",
        "    data = data.to(device=device) # Get data to cuda if possible and ensure all our computation is on the same device\n",
        "    targets = targets.to(device=device)\n",
        "\n",
        "    # Get to correct shape\n",
        "    # -1 will flatten all outer dimensions into one\n",
        "    data = data.reshape(data.shape[0], -1)  # data is originially of the shape 1,28,28\n",
        "                                            # sice we are passing 64 samples of shape 1,28,28 at once through the model\n",
        "                                            # thus the reshaped tensor is of shape 1,(28*28)= 1,784\n",
        "\n",
        "    print(data.shape) # confirming our data is properly reshaped\n",
        "\n",
        "    print(targets)\n",
        "    print(targets.shape)\n",
        "\n",
        "    scores = model(data)  # making our predictions i.e. running the data through the model\n",
        "\n",
        "    print(scores)\n",
        "    print(scores.shape) # checking that we have the right shape.. which is?\n",
        "\n",
        "    loss = criterion(scores, targets) # calculating the loss\n",
        "    print(loss)\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFwtdbTQoMHj",
        "outputId": "2f5c718c-3f3a-483e-eec1-febe9d6c6ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 1, 4, 0, 3, 2, 9, 1, 6, 5, 3, 7, 8, 0, 7, 3, 2, 7, 7, 1, 6, 8, 7, 3,\n",
            "        9, 4, 4, 1, 7, 1, 0, 1, 6, 4, 0, 3, 3, 7, 0, 6, 1, 8, 7, 6, 2, 3, 1, 5,\n",
            "        9, 0, 2, 9, 1, 9, 5, 5, 7, 8, 2, 9, 1, 0, 7, 7])\n",
            "tensor([[ 9.8769e-02, -5.3561e-02, -2.0750e-02, -1.3181e-01, -1.0053e-01,\n",
            "          6.0082e-03, -1.3565e-01,  1.6104e-01,  1.1245e-01, -1.2824e-02],\n",
            "        [ 3.9910e-02, -1.2318e-02, -1.4538e-02, -1.6280e-01, -1.8012e-01,\n",
            "          7.1712e-02, -4.4927e-02,  9.5309e-02,  9.0295e-02, -2.4906e-02],\n",
            "        [ 4.0028e-02, -1.5994e-01, -5.8433e-02, -1.2640e-01, -7.4184e-02,\n",
            "          4.7739e-02, -1.3751e-01,  1.8580e-01,  1.5276e-01, -2.5543e-02],\n",
            "        [-5.6897e-02,  6.5495e-02, -1.7964e-01, -7.5689e-02, -9.4032e-02,\n",
            "          1.2958e-01, -1.0266e-01,  1.3185e-01,  1.3364e-01, -1.3666e-02],\n",
            "        [ 3.0614e-02, -3.6379e-02, -2.9704e-02, -8.0381e-02, -1.5200e-01,\n",
            "          4.3632e-02, -1.3486e-01,  1.2182e-01,  1.5284e-01,  9.2177e-02],\n",
            "        [ 1.7199e-01, -3.0306e-02, -3.3915e-02, -1.1225e-01, -1.5516e-01,\n",
            "         -7.1529e-02, -6.7793e-02,  2.1604e-01,  4.6159e-02,  9.7358e-02],\n",
            "        [ 5.6274e-02, -1.0636e-01, -7.0849e-02, -1.1366e-01, -8.3706e-02,\n",
            "          3.9585e-02, -1.5598e-01,  1.6579e-01,  1.2643e-01, -8.4693e-02],\n",
            "        [ 8.8842e-02, -5.5423e-02, -4.5136e-02, -1.2040e-01, -1.3458e-01,\n",
            "         -3.1985e-02, -1.2860e-01,  1.1176e-01,  1.1571e-01, -1.0623e-02],\n",
            "        [ 1.5413e-01, -1.3630e-01, -3.9629e-02, -1.2117e-01, -1.2877e-01,\n",
            "         -3.7108e-02, -9.9287e-02,  1.9766e-01,  4.3137e-02, -3.0420e-02],\n",
            "        [ 1.4133e-02, -7.0297e-02, -9.2936e-02, -1.1965e-01, -7.1722e-02,\n",
            "          8.6224e-02, -1.3933e-01,  1.3504e-01,  1.1762e-01, -7.7871e-02],\n",
            "        [ 1.1499e-01, -6.9281e-02, -3.1310e-02, -7.0288e-02, -1.2598e-01,\n",
            "          6.2231e-02, -5.4918e-02,  1.8161e-01,  8.8843e-02, -7.2123e-02],\n",
            "        [ 9.7441e-02, -2.2356e-02, -1.0540e-02, -9.5096e-02, -1.1952e-01,\n",
            "         -1.4802e-03, -1.0477e-01,  9.0076e-02,  1.3755e-01,  5.3889e-03],\n",
            "        [ 7.4666e-02, -1.3754e-01, -5.2062e-02, -1.9929e-01, -1.2215e-01,\n",
            "          6.7402e-02, -1.7271e-01,  1.9474e-01,  1.3064e-01, -3.3359e-02],\n",
            "        [ 1.0119e-01, -5.6276e-02, -3.3393e-02, -1.2200e-01, -1.0077e-01,\n",
            "         -8.4319e-03,  6.2884e-02,  2.0486e-01,  1.5030e-01, -1.3016e-01],\n",
            "        [ 7.3683e-02, -1.4452e-02, -1.8317e-02, -1.0348e-01, -1.3379e-01,\n",
            "         -2.9371e-03, -1.2400e-01,  9.4243e-02,  9.3306e-02,  1.8042e-02],\n",
            "        [ 8.7332e-02, -8.8955e-02, -1.0419e-01, -1.3331e-01, -1.1551e-01,\n",
            "          1.3089e-01, -2.1760e-01,  1.6976e-01,  1.1486e-01, -1.4090e-02],\n",
            "        [ 9.5962e-02, -9.4505e-02, -1.2756e-01, -2.2434e-01, -6.2670e-02,\n",
            "          5.4017e-02, -1.2646e-01,  2.4593e-01,  1.1089e-01, -1.0184e-01],\n",
            "        [ 4.4493e-02, -3.0662e-02, -1.7947e-02, -6.8359e-02, -1.8560e-01,\n",
            "          6.0896e-02, -1.1710e-01,  8.0011e-02,  1.2009e-01, -7.7920e-03],\n",
            "        [ 8.4570e-02, -2.2160e-02, -1.4439e-01, -1.4125e-01, -7.7433e-02,\n",
            "          4.7681e-02, -1.3282e-01,  1.1481e-01,  1.7312e-01, -4.7055e-02],\n",
            "        [ 1.1865e-01, -6.4789e-02, -5.9225e-02, -8.3843e-02, -1.6966e-01,\n",
            "         -1.8322e-02, -1.5312e-01,  1.6490e-01,  1.4797e-01,  7.0885e-04],\n",
            "        [-3.8790e-03, -1.3263e-01, -1.2686e-01, -1.1088e-01, -1.0387e-01,\n",
            "          7.2863e-02, -4.8444e-02,  1.7458e-01,  1.0458e-01,  5.9568e-02],\n",
            "        [ 5.0634e-02,  3.3824e-02, -3.5100e-02, -1.1285e-01, -1.9062e-01,\n",
            "          1.3547e-01, -1.3439e-01,  1.6296e-01,  1.1683e-01, -5.2970e-02],\n",
            "        [ 5.1076e-02, -5.5169e-02, -6.3256e-02, -7.9984e-03, -1.1554e-01,\n",
            "          1.1850e-01,  4.4233e-02,  1.0592e-01,  9.0377e-02, -8.0313e-02],\n",
            "        [-3.0715e-02, -5.8190e-02, -1.2720e-01, -1.3569e-01, -1.9192e-01,\n",
            "          1.3358e-01, -1.5458e-01,  1.6736e-01,  7.4697e-02, -4.8765e-02],\n",
            "        [ 1.7632e-02, -4.1384e-02, -2.5569e-01, -5.5757e-02, -6.1183e-02,\n",
            "          4.7076e-02, -1.2792e-01,  6.9582e-02,  5.3425e-02,  2.7726e-02],\n",
            "        [-4.0577e-02, -2.0335e-02, -2.3375e-01, -1.5992e-01, -6.8332e-02,\n",
            "          1.2364e-01, -7.0492e-02,  1.2454e-01,  1.1236e-01, -4.8532e-02],\n",
            "        [ 2.5159e-02, -1.8739e-02, -9.5133e-02, -1.2617e-01, -8.7798e-02,\n",
            "          1.0894e-01,  3.8692e-03,  1.2740e-01,  6.5281e-02,  1.3110e-02],\n",
            "        [ 9.4938e-02, -4.3547e-02, -6.6195e-02, -9.8519e-02, -1.8431e-01,\n",
            "         -1.6843e-02, -7.1814e-02,  1.3418e-01,  1.1163e-01, -4.7116e-03],\n",
            "        [ 4.1331e-02, -9.5235e-02, -6.8159e-02, -9.2147e-02, -1.0059e-01,\n",
            "          6.2975e-02,  2.4095e-02,  3.5399e-02,  1.1143e-01,  1.6447e-02],\n",
            "        [ 4.1748e-02, -1.0840e-01,  4.1997e-02, -1.5980e-01, -1.4614e-01,\n",
            "          9.5469e-03, -9.1693e-02,  1.6743e-01,  8.4431e-02, -1.4303e-02],\n",
            "        [ 1.1525e-03,  5.7781e-02, -8.0832e-02, -1.6532e-01, -7.5758e-02,\n",
            "          1.9965e-01, -5.3299e-02,  1.4731e-01,  1.3186e-01, -1.0669e-01],\n",
            "        [ 1.4628e-02, -3.3138e-02,  3.0022e-02, -1.4998e-01, -1.3281e-01,\n",
            "          2.0948e-02, -1.3622e-01,  9.0026e-02,  1.4434e-01,  2.9440e-02],\n",
            "        [ 5.7750e-02, -6.8999e-02, -9.3222e-02, -1.2804e-01, -1.4085e-01,\n",
            "          6.9699e-02, -9.4178e-02,  1.7893e-01,  7.1441e-02,  3.5665e-02],\n",
            "        [ 3.3122e-02, -3.4865e-02, -9.0494e-02, -9.3533e-02, -1.0334e-01,\n",
            "          3.9363e-02, -1.1471e-01,  1.8104e-01,  2.9391e-02, -2.3276e-02],\n",
            "        [ 7.7777e-02, -5.9022e-03, -1.4824e-01, -9.1150e-02, -1.2532e-01,\n",
            "          1.6083e-01, -3.7359e-02,  1.7058e-01,  1.5922e-01, -1.6009e-01],\n",
            "        [-1.9929e-03,  5.7519e-02, -1.2160e-01, -8.8841e-02, -1.7388e-01,\n",
            "          2.2198e-01, -1.3929e-01,  1.0579e-01,  2.0166e-01, -6.4595e-02],\n",
            "        [-1.2371e-03,  5.7962e-04, -6.0852e-02, -4.8602e-02, -1.1679e-01,\n",
            "          6.6129e-02, -1.9413e-01,  1.3610e-01,  1.5407e-01,  1.4630e-02],\n",
            "        [ 9.9107e-02,  1.2188e-02, -6.2376e-02, -1.4823e-01, -1.1265e-01,\n",
            "          1.1322e-02, -3.0179e-02,  1.2263e-01,  1.1968e-01, -9.2070e-03],\n",
            "        [ 1.7718e-01, -4.5545e-02, -9.9809e-03, -1.2912e-01, -1.4961e-01,\n",
            "          1.2920e-01,  1.7051e-02,  2.2738e-01,  8.0749e-02, -1.5576e-01],\n",
            "        [ 4.8374e-02,  4.3437e-02, -2.3178e-02, -7.4036e-02, -1.2608e-01,\n",
            "          9.2623e-02, -5.8516e-02,  1.0465e-01,  7.8892e-02,  1.8382e-02],\n",
            "        [ 1.1391e-01, -5.1480e-02, -1.1316e-01, -8.3540e-02, -2.0154e-01,\n",
            "         -3.5543e-02, -4.6639e-02,  1.1915e-01,  1.1568e-01, -7.8120e-03],\n",
            "        [ 5.8424e-02, -4.7794e-02, -1.4726e-01, -4.5602e-02, -1.6899e-01,\n",
            "          7.3084e-02, -1.0171e-01,  1.3397e-01,  7.0124e-02,  9.1900e-02],\n",
            "        [ 7.4025e-02, -6.6211e-02, -2.0513e-02, -1.7087e-01, -1.4073e-01,\n",
            "          5.1053e-02,  4.9957e-03,  1.2444e-01,  9.0663e-02, -3.0137e-02],\n",
            "        [ 1.1632e-02, -2.8677e-02, -1.8356e-01, -1.7019e-01, -1.0231e-01,\n",
            "          2.5526e-02, -5.9080e-02,  1.8716e-01,  5.5446e-02, -3.5894e-02],\n",
            "        [ 8.0333e-02, -6.3539e-02, -2.1965e-01, -1.8283e-01, -1.4564e-01,\n",
            "          1.6891e-01, -1.2875e-01,  1.1010e-01,  1.4492e-01, -1.2038e-01],\n",
            "        [ 1.3566e-03, -4.6098e-02, -9.0888e-02, -1.5715e-01, -1.2049e-01,\n",
            "          1.3324e-01, -1.7639e-01,  1.5197e-01,  1.5135e-01, -8.4594e-02],\n",
            "        [ 6.1030e-02, -3.4957e-02, -4.9509e-02, -1.2939e-01, -1.2206e-01,\n",
            "         -8.3371e-03, -1.6673e-01,  1.2654e-01,  1.6079e-01,  1.4027e-02],\n",
            "        [ 9.2570e-02, -7.2448e-02, -1.5071e-02, -1.2355e-01, -2.1108e-01,\n",
            "          7.0737e-02, -9.9376e-02,  1.1369e-01,  1.6880e-01,  4.4480e-05],\n",
            "        [ 7.7199e-02, -5.1740e-02, -7.1031e-02, -1.0737e-01, -1.1629e-01,\n",
            "          2.5534e-02, -1.2927e-01,  1.2481e-01,  1.6109e-01, -4.8987e-02],\n",
            "        [ 1.4198e-01,  6.1540e-03, -9.3638e-02, -6.3984e-02, -6.4005e-02,\n",
            "          1.0714e-01,  3.9280e-03,  1.2098e-01,  1.8465e-01, -1.3127e-01],\n",
            "        [-3.0744e-02, -5.9600e-02, -2.1112e-01, -2.8595e-02, -7.7364e-02,\n",
            "          7.7658e-02, -1.9558e-01,  7.0752e-02,  8.6019e-02,  5.4197e-03],\n",
            "        [ 8.3371e-02,  6.2467e-03, -9.1775e-02, -5.7620e-02, -1.0693e-01,\n",
            "          4.0086e-02, -1.4838e-01,  1.3997e-01,  9.0804e-02,  7.3806e-03],\n",
            "        [ 1.7363e-01, -8.3253e-02, -3.3942e-02, -7.7438e-02, -1.9390e-01,\n",
            "          3.8062e-02, -9.4577e-02,  2.2858e-01,  1.4319e-01, -3.8503e-02],\n",
            "        [ 6.0799e-02,  1.4323e-02,  1.2243e-03, -1.6675e-01, -1.1839e-01,\n",
            "          3.6078e-02, -3.4888e-02,  1.5168e-01,  1.0968e-01, -5.2880e-02],\n",
            "        [ 7.5058e-03, -5.0271e-02, -6.0615e-02, -1.0684e-01, -7.0284e-02,\n",
            "          7.5894e-02, -1.9842e-01,  1.2584e-01,  1.3242e-01, -2.3029e-02],\n",
            "        [ 1.1252e-01,  3.1144e-02, -4.4227e-03, -1.3564e-01, -4.5307e-02,\n",
            "          1.6607e-02, -1.0552e-01,  1.9837e-01,  1.4559e-01, -2.3094e-02],\n",
            "        [ 3.6818e-02, -7.8047e-04, -1.0921e-01, -1.9742e-01, -7.6849e-02,\n",
            "          1.4501e-01, -1.7786e-01,  1.1344e-01,  2.0522e-01,  2.5944e-02],\n",
            "        [ 6.2999e-02, -4.7515e-03, -2.6591e-01, -7.1769e-02, -5.2792e-03,\n",
            "          1.3681e-01, -1.9955e-01,  1.3507e-01,  1.1885e-01, -1.5453e-01],\n",
            "        [ 1.2574e-01, -4.3203e-02, -8.1477e-02, -1.0442e-01, -8.6889e-02,\n",
            "          1.4788e-02, -1.0826e-01,  1.6876e-01,  5.1460e-02, -3.7791e-03],\n",
            "        [ 4.2038e-02, -1.0106e-01, -1.0420e-01, -7.9322e-02, -9.4301e-02,\n",
            "          9.0419e-02, -9.5778e-02,  9.7664e-02,  1.6499e-01, -5.2707e-02],\n",
            "        [ 9.7134e-02, -6.9285e-02, -6.1496e-02, -1.3540e-01, -1.6521e-01,\n",
            "         -4.8164e-02, -1.3525e-01,  1.5345e-01,  1.2995e-01, -1.2949e-02],\n",
            "        [ 1.3939e-02, -2.5866e-03, -1.8240e-01, -1.0133e-01, -1.3808e-01,\n",
            "          1.7456e-01, -6.3907e-02,  1.2481e-01,  1.6279e-01, -1.5625e-01],\n",
            "        [ 6.7404e-02, -1.0699e-01,  5.5485e-02, -1.4152e-01, -2.1873e-01,\n",
            "          2.7102e-02,  3.8680e-02,  1.3401e-01,  8.0309e-02,  7.4645e-02],\n",
            "        [ 1.0692e-01, -6.3687e-02, -3.3831e-02, -1.1261e-01, -1.2179e-01,\n",
            "          6.4709e-02, -6.2230e-02,  1.1995e-01,  1.5318e-01,  7.0669e-03]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([64, 10])\n",
            "tensor(2.3073, grad_fn=<NllLossBackward0>)\n",
            "tensor([0, 2, 1, 5, 0, 7, 1, 7, 7, 2, 1, 2, 3, 2, 2, 6, 4, 0, 4, 0, 8, 1, 2, 0,\n",
            "        1, 0, 3, 2, 3, 2, 8, 6])\n",
            "tensor([[ 0.0194,  0.0371, -0.1552, -0.0342, -0.0120,  0.0868, -0.1215,  0.0265,\n",
            "          0.1723, -0.0894],\n",
            "        [ 0.1041, -0.0137, -0.0463, -0.1452, -0.1474,  0.0353, -0.1700,  0.1905,\n",
            "          0.0809,  0.0034],\n",
            "        [ 0.0616, -0.0960,  0.0119, -0.1466, -0.1374,  0.0038, -0.0726,  0.0899,\n",
            "          0.1177,  0.0215],\n",
            "        [-0.0015,  0.0418, -0.1162, -0.0643, -0.0231,  0.0847, -0.2053,  0.0503,\n",
            "          0.1611, -0.0358],\n",
            "        [ 0.0564,  0.0536, -0.0572, -0.0624, -0.1865,  0.0782, -0.0715,  0.1954,\n",
            "          0.0846,  0.0016],\n",
            "        [ 0.0556, -0.0456, -0.0860, -0.1498, -0.0768,  0.0392, -0.1484,  0.1263,\n",
            "          0.1541,  0.0331],\n",
            "        [ 0.0341, -0.0733,  0.0571, -0.1470, -0.1673, -0.0397, -0.0934,  0.1278,\n",
            "          0.1234, -0.0090],\n",
            "        [ 0.0817, -0.0173, -0.1016, -0.0784, -0.0425,  0.0723, -0.1216,  0.1022,\n",
            "          0.1283,  0.0738],\n",
            "        [ 0.0204, -0.0265, -0.1334, -0.0824, -0.1221,  0.1244, -0.0965,  0.0823,\n",
            "          0.1343, -0.1160],\n",
            "        [ 0.0511, -0.0945, -0.0981, -0.0689, -0.1278, -0.0047, -0.0406,  0.1175,\n",
            "          0.0319, -0.0105],\n",
            "        [ 0.0692, -0.0534, -0.0360, -0.1430, -0.1104, -0.0133, -0.1244,  0.1336,\n",
            "          0.1315,  0.0461],\n",
            "        [ 0.1057, -0.0328, -0.1400, -0.0579, -0.1412,  0.0199, -0.1167,  0.1072,\n",
            "          0.0920, -0.0304],\n",
            "        [ 0.0320, -0.0458, -0.0430, -0.1347, -0.1887,  0.0271, -0.1238,  0.1681,\n",
            "          0.1072,  0.0273],\n",
            "        [ 0.0887, -0.0472, -0.1638, -0.1052, -0.0331,  0.0481, -0.1838,  0.1555,\n",
            "          0.1079,  0.0064],\n",
            "        [ 0.0558, -0.0963,  0.0275, -0.1054, -0.1197,  0.0168, -0.0523,  0.1651,\n",
            "          0.0727,  0.0266],\n",
            "        [ 0.1073, -0.0656,  0.0056, -0.1038, -0.1091,  0.0191, -0.0006,  0.1576,\n",
            "          0.0759,  0.0081],\n",
            "        [ 0.0846, -0.0691, -0.0994, -0.1161, -0.0420,  0.0918, -0.0971,  0.1870,\n",
            "          0.0984, -0.0948],\n",
            "        [ 0.0217,  0.0837, -0.1240, -0.0370, -0.0282,  0.1000, -0.1602,  0.0087,\n",
            "          0.1353, -0.0506],\n",
            "        [ 0.0888, -0.0271, -0.0393, -0.1278, -0.0847,  0.0215, -0.0690,  0.1170,\n",
            "          0.1028, -0.0069],\n",
            "        [-0.0785,  0.0856, -0.1140, -0.1665, -0.1189,  0.2223, -0.0111,  0.1673,\n",
            "          0.0898, -0.0623],\n",
            "        [ 0.0387, -0.0279, -0.1405, -0.1091, -0.1095,  0.1099, -0.1339,  0.1868,\n",
            "          0.0842, -0.0336],\n",
            "        [ 0.1102, -0.0559, -0.0550, -0.1193, -0.1765, -0.0187, -0.1138,  0.0873,\n",
            "          0.1425, -0.0270],\n",
            "        [ 0.0180, -0.0447, -0.0272, -0.0172, -0.1795,  0.0501, -0.1276,  0.1193,\n",
            "          0.0659,  0.0857],\n",
            "        [ 0.0782,  0.0272, -0.1432, -0.0452, -0.0869,  0.0511, -0.1890,  0.1610,\n",
            "          0.1242, -0.0170],\n",
            "        [ 0.0157, -0.1128,  0.0256, -0.1344, -0.1948, -0.0128, -0.0833,  0.1147,\n",
            "          0.1059, -0.0321],\n",
            "        [-0.0003, -0.0322, -0.0532, -0.0878, -0.1174,  0.0642, -0.1475,  0.1120,\n",
            "          0.1009,  0.0654],\n",
            "        [ 0.0830, -0.0387, -0.1303, -0.1000, -0.2739,  0.1787, -0.1156,  0.1609,\n",
            "          0.1027, -0.1034],\n",
            "        [ 0.0810,  0.0480, -0.0810, -0.1226, -0.1612,  0.1308, -0.1783,  0.2576,\n",
            "          0.1191,  0.0104],\n",
            "        [ 0.0308,  0.0161, -0.0864, -0.0854, -0.1610,  0.1322, -0.1413,  0.0994,\n",
            "          0.0991,  0.0111],\n",
            "        [ 0.1290, -0.0694, -0.1032, -0.2393, -0.1096,  0.0683, -0.1289,  0.2745,\n",
            "          0.1505, -0.1078],\n",
            "        [ 0.0100,  0.0384, -0.1152, -0.0432, -0.1457,  0.1484, -0.1765,  0.0560,\n",
            "          0.1372,  0.0589],\n",
            "        [ 0.0683, -0.0119, -0.0651, -0.0390, -0.0539,  0.0547, -0.0935,  0.1903,\n",
            "          0.1223, -0.0076]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([32, 10])\n",
            "tensor(2.3260, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "ROM9fUVaB177"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Get to correct shape, 28x28->784\n",
        "        # -1 will flatten all outer dimensions into one\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # zero previous gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # back-propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or in this case: adam step\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6tRGQvNlqri",
        "outputId": "9a61e69b-f15f-4268-e9b1-61bf8960d180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Epoch: 1\n",
            "Epoch: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking accuracy"
      ],
      "metadata": {
        "id": "LFUfiNluB87-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # puts the model in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader: # here x and y are your input image as a tensor and targets\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0], -1) # reshaping data before putting it into our model, as we did earlier\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)  # your model is essentially predicting whichever values of the 10 classes is maximum\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy\"\n",
        "            f\" {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
        "        )\n",
        "\n",
        "    model.train() # this is strictly speaking not necessary since we are not training the model after this,\n",
        "                  # but if we checked accuracy mid training it is needed"
      ],
      "metadata": {
        "id": "pLPttiB0mCs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiltZv7umKT7",
        "outputId": "8a7f984d-592f-46c2-9727-79c1f71aceb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 57595 / 60000 with accuracy 95.99\n",
            "Got 9547 / 10000 with accuracy 95.47\n"
          ]
        }
      ]
    }
  ]
}